{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e69509d",
   "metadata": {},
   "source": [
    "the ChatGPT conversation that I used can be found here:\n",
    "https://chat.openai.com/share/54ab32b8-27d0-43fd-b575-25a82712b2a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5473b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy.stats as st\n",
    "\n",
    "from scipy.stats import bernoulli, binom, poisson, chi2\n",
    "from IPython.display import clear_output\n",
    "from operator import itemgetter\n",
    "from statsmodels.stats import proportion\n",
    "\n",
    "from numpy import matlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07c9f34",
   "metadata": {},
   "source": [
    "Exercise 1\n",
    "Assume that there are 10 quanta available in a nerve terminal, and for a given release event each is released with a probability of 0.2. For one such event, what is the probability that 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, or 10 quanta will be released?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b1250",
   "metadata": {},
   "source": [
    "I generated the following code using ChatGPT by giving it the following prompt:\n",
    "\"write me python code for the following: Assume that there are 10 quanta available in a nerve terminal, and for a given release event each is released with a probability of 0.2. For one such event, what is the probability that 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, or 10 quanta will be released?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3ade73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 0 quanta released: 0.1074\n",
      "Probability of 1 quanta released: 0.2684\n",
      "Probability of 2 quanta released: 0.3020\n",
      "Probability of 3 quanta released: 0.2013\n",
      "Probability of 4 quanta released: 0.0881\n",
      "Probability of 5 quanta released: 0.0264\n",
      "Probability of 6 quanta released: 0.0055\n",
      "Probability of 7 quanta released: 0.0008\n",
      "Probability of 8 quanta released: 0.0001\n",
      "Probability of 9 quanta released: 0.0000\n",
      "Probability of 10 quanta released: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "total_quanta = 10\n",
    "release_probability = 0.2\n",
    "\n",
    "# Initialize a list to store the probabilities for each outcome\n",
    "probabilities = []\n",
    "\n",
    "# Calculate the probability for 0 to 10 quanta being released\n",
    "for i in range(total_quanta + 1):\n",
    "    probability = binom.pmf(i, total_quanta, release_probability)\n",
    "    probabilities.append((i, probability))\n",
    "\n",
    "# Print the probabilities\n",
    "for outcome, probability in probabilities:\n",
    "    print(f\"Probability of {outcome} quanta released: {probability:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22bc82",
   "metadata": {},
   "source": [
    "Exercise 2\n",
    "Let's say you know that a given nerve terminal contains exactly 14 quanta available for release. You have read in the literature that the release probability of these quanta is low, say 0.1. To assess whether this value is reasonable, you run a simple experiment: activate the nerve and measure the number of quanta that are released. The result is 8 quanta. What is the probability that you would get this result (8 quanta) if the true probability of release really was 0.1? What about if the true release probability was much higher; say, 0.7? What about for each decile of release probability (0.1, 0.2, ... 1.0)? Which value of release probability did you determine to be the most probable, given your measurement?\n",
    "\n",
    "Note: here you are computing a likelihood function: a function describing how the value of the conditional probability p(data | parameters) changes when you hold your data fixed to the value(s) you measured and vary the value(s) of the parameter(s) of, in this case, the binomial distribution. Because you are varying the parameters and not the data, the values of the function are not expected to sum to one (e.g., you can have numerous parameters that have a very high probability of producing the given data) and thus this function is not a probability distribution (see here for an extended discussion). The maximum value of this function is called the maximum likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd568664",
   "metadata": {},
   "source": [
    "I generated the following code using ChatGPT and giving it the following prompt: \n",
    "\"Write me python code for the following: There is a nerve terminal with 14 quanta available for release. You activate the nerve and measure 8 quanta released. What is the probability of getting this result if the probability of release was 0.1 to 1 in increments of 0.1? Compute a likelihood function.\"\n",
    "\n",
    "I modified in slightly to show results as decimals instead of e\n",
    "\n",
    "The most probable release probability given the measurements is 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b24c40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of release = 0.1: Likelihood = 0.0000\n",
      "Probability of release = 0.2: Likelihood = 0.0020\n",
      "Probability of release = 0.3: Likelihood = 0.0232\n",
      "Probability of release = 0.4: Likelihood = 0.0918\n",
      "Probability of release = 0.5: Likelihood = 0.1833\n",
      "Probability of release = 0.6: Likelihood = 0.2066\n",
      "Probability of release = 0.7: Likelihood = 0.1262\n",
      "Probability of release = 0.8: Likelihood = 0.0322\n",
      "Probability of release = 0.9: Likelihood = 0.0013\n",
      "Probability of release = 1.0: Likelihood = 0.0000\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "total_quanta = 14\n",
    "observed_quanta = 8\n",
    "probability_range = np.arange(0.1, 1.1, 0.1)\n",
    "\n",
    "# Initialize a list to store the likelihoods for each probability\n",
    "likelihoods = []\n",
    "\n",
    "# Calculate the likelihood for each probability in the range\n",
    "for p_release in probability_range:\n",
    "    likelihood = binom.pmf(observed_quanta, total_quanta, p_release)\n",
    "    likelihoods.append((p_release, likelihood))\n",
    "\n",
    "# Print the likelihoods\n",
    "for p_release, likelihood in likelihoods:\n",
    "    print(f\"Probability of release = {p_release:.1f}: Likelihood = {likelihood:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062f7502",
   "metadata": {},
   "source": [
    "Exercise 3\n",
    "Not feeling convinced by your single experiment (good scientist!), you repeat it under identical conditions. This time you measure 5 quanta that were released. Your sample size has now doubled, to two measurements. You now want to take into account both measurements when you assess the likelihoods of different possible values of the underlying release probability. To do so, assume that the two measurements in this sample are independent of one another; that is, the value of each result had no bearing on the other. In this case, the total likelihood is simply the product of the likelihoods associated with each separate measurement. It is also typical to compute the logarithm of each likelihood and take their sum, which is often more convenient. What are the values of the total likelihood and total log-likelihood in this example, if we assume that the true release probability is 0.1?\n",
    "\n",
    "Of course, knowing those values of the likelihood and log-likelihood is not particularly useful until you can compare them to the values computed for other possible values for the release probability, so you can determine which value of release probability is most likely, given the data. Therefore, compute the full likelihood and log-likelihood functions using deciles of release probability between 0 and 1. What is the maximum value? Can you improve your estimate by computing the functions at a higher resolution? How does the estimate improve as you increase the sample size?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e118c",
   "metadata": {},
   "source": [
    "Write me python code for the following: \n",
    "\"There is a nerve terminal with 14 quanta available for release. You activate the nerve and measure 8 quanta released. You activate it again in an independent experiment and measure 5 quanta. What is the probability of getting this result if the probability of release was 0.1 to 1 in increments of 0.1? Compute a likelihood function, where the total likelihood is the product of the likelihood of each separate measurement. Compute the log-likelihood funciton by computing the sum of the logarithm of each likelihood. Repeat the above code using probabilities of release from 0.05 to 1 in increments of 0.05.\"\n",
    "\n",
    "In the first iteration, the code only printed the total likelihood, so I had to prompt it to also print the log-likelihood. I also had to fix the log likelihood equation (it was just taking the log of the total likelihood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24722f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of release = 0.05: Total Likelihood = 0.0000, Log-Likelihood = -inf\n",
      "Probability of release = 0.10: Total Likelihood = 0.0000, Log-Likelihood = -inf\n",
      "Probability of release = 0.15: Total Likelihood = 0.0000, Log-Likelihood = -inf\n",
      "Probability of release = 0.20: Total Likelihood = 0.0002, Log-Likelihood = -inf\n",
      "Probability of release = 0.25: Total Likelihood = 0.0012, Log-Likelihood = -inf\n",
      "Probability of release = 0.30: Total Likelihood = 0.0046, Log-Likelihood = -inf\n",
      "Probability of release = 0.35: Total Likelihood = 0.0111, Log-Likelihood = -inf\n",
      "Probability of release = 0.40: Total Likelihood = 0.0190, Log-Likelihood = -inf\n",
      "Probability of release = 0.45: Total Likelihood = 0.0238, Log-Likelihood = -inf\n",
      "Probability of release = 0.50: Total Likelihood = 0.0224, Log-Likelihood = -inf\n",
      "Probability of release = 0.55: Total Likelihood = 0.0159, Log-Likelihood = -inf\n",
      "Probability of release = 0.60: Total Likelihood = 0.0084, Log-Likelihood = -inf\n",
      "Probability of release = 0.65: Total Likelihood = 0.0032, Log-Likelihood = -inf\n",
      "Probability of release = 0.70: Total Likelihood = 0.0008, Log-Likelihood = -inf\n",
      "Probability of release = 0.75: Total Likelihood = 0.0001, Log-Likelihood = -inf\n",
      "Probability of release = 0.80: Total Likelihood = 0.0000, Log-Likelihood = -inf\n",
      "Probability of release = 0.85: Total Likelihood = 0.0000, Log-Likelihood = -inf\n",
      "Probability of release = 0.90: Total Likelihood = 0.0000, Log-Likelihood = -inf\n",
      "Probability of release = 0.95: Total Likelihood = 0.0000, Log-Likelihood = -inf\n",
      "Probability of release = 1.00: Total Likelihood = 0.0000, Log-Likelihood = -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesd1\\AppData\\Local\\Temp\\ipykernel_22684\\4017245815.py:23: RuntimeWarning: divide by zero encountered in log\n",
      "  log_likelihood = np.log(likelihood1) + np.log(likelihood2)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "total_quanta = 14\n",
    "observed_quanta1 = 8\n",
    "observed_quanta2 = 5\n",
    "probability_range = np.arange(0.05, 1.05, 0.05)\n",
    "\n",
    "# Initialize a list to store the likelihoods and log-likelihoods for each probability\n",
    "likelihoods = []\n",
    "log_likelihoods = []\n",
    "\n",
    "# Calculate the likelihood and log-likelihood for each probability in the range\n",
    "for p_release in probability_range:\n",
    "    likelihood1 = binom.pmf(observed_quanta1, total_quanta, p_release)\n",
    "    likelihood2 = binom.pmf(observed_quanta2, total_quanta, p_release)\n",
    "    \n",
    "    # Calculate the total likelihood as the product of the likelihoods\n",
    "    total_likelihood = likelihood1 * likelihood2\n",
    "    \n",
    "    # Calculate the log-likelihood as the sum of the logarithm of each likelihood\n",
    "    log_likelihood = np.log(likelihood1) + np.log(likelihood2)\n",
    "    \n",
    "    likelihoods.append((p_release, total_likelihood))\n",
    "    log_likelihoods.append((p_release, log_likelihood))\n",
    "\n",
    "# Print the likelihoods and log-likelihoods\n",
    "for p_release, total_likelihood in likelihoods:\n",
    "    log_likelihood = next(log_likelihood for prob, log_like in log_likelihoods if prob == p_release)\n",
    "    print(f\"Probability of release = {p_release:.2f}: Total Likelihood = {total_likelihood:.4f}, Log-Likelihood = {log_likelihood:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462c280c",
   "metadata": {},
   "source": [
    "Exercise 4\n",
    "You keep going and conduct 100 separate experiments and end up with these results:\n",
    "\n",
    "Measured releases\tCount\n",
    "0\t0\n",
    "1\t0\n",
    "2\t3\n",
    "4\t10\n",
    "5\t19\n",
    "6\t26\n",
    "7\t16\n",
    "8\t16\n",
    "9\t5\n",
    "10\t5\n",
    "11\t0\n",
    "12\t0\n",
    "13\t0\n",
    "14\t0\n",
    "What is the most likely value of p (which we typically refer to as \n",
    "p-hat, which is pronounced as \"p-hat\" and represents the maximum-likelihood estimate of a parameter in the population given our sample with a resolution of 0.01?\n",
    "\n",
    "BONUS: Use a fitting procedure to find p-hat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b93d06",
   "metadata": {},
   "source": [
    "I used the following ChatGPT prompt:\n",
    "\n",
    "\"Write me python code for the following: \n",
    "You conduct the same experiment as above 100 times and get the following data:\n",
    "measured_releases = np.arange(1,15,1)\n",
    "count = [0,0,3,10,19,26,16,16,5,5,0,0,0,0]\n",
    "Write python code to calculate the most likely value of probability of release, where probability of release is between 0 and 1 in increments of 0.1.\"\n",
    "\n",
    "I modified the code to print the answer to one decimal point instead of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aaff33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Likelihood Estimate for p_release: 0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "# Given data\n",
    "measured_releases = np.arange(1, 15, 1)\n",
    "count = [0, 0, 3, 10, 19, 26, 16, 16, 5, 5, 0, 0, 0, 0]\n",
    "\n",
    "# Function to compute the negative log-likelihood\n",
    "def negative_log_likelihood(p_release):\n",
    "    likelihood = 0.0\n",
    "    for observed, c in zip(measured_releases, count):\n",
    "        likelihood += c * np.log(binom.pmf(observed, total_quanta, p_release))\n",
    "    return -likelihood\n",
    "\n",
    "# Constants\n",
    "total_quanta = 14\n",
    "\n",
    "# Find the maximum likelihood estimate for p_release\n",
    "result = minimize_scalar(negative_log_likelihood, bounds=(0, 1), method='bounded')\n",
    "\n",
    "# The MLE estimate for p_release\n",
    "mle_p_release = result.x\n",
    "\n",
    "print(f\"Maximum Likelihood Estimate for p_release: {mle_p_release:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47c8518",
   "metadata": {},
   "source": [
    "Exercise 5\n",
    "Let's say that you have run an exhaustive set of experiments on this synapse and have determined that the true release probability is 0.3 (within some very small tolerance). Now you want to test whether changing the temperature of the preparation affects the release probability. So you change the temperature, perform the experiment, and measure 7 quantal events for the same 14 available quanta. Compute p-hat\n",
    ". Standard statistical inference now asks the question, what is the probability that you would have obtained that measurement given a Null Hypothesis of no effect? In this case, no effect corresponds to an unchanged value of the true release probability (i.e., its value remained at 0.3 even with the temperature change). What is the probability that you would have gotten that measurement if your Null Hypothesis were true? Can you conclude that temperature had an effect?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30382b9b",
   "metadata": {},
   "source": [
    "I used the following prompt for ChatGPT:\n",
    "\"You conduct the same experiment as above with 14 available quanta and measure 7 quantal events.\n",
    "Write python code to calculate the most likely value of probability of release, where probability of release is between 0 and 1 in increments of 0.1.\n",
    "Write python code to calculate the probability of getting this probability of release given the the true probability of release is 0.3.\"\n",
    "\n",
    "In this case, the p value is more that 0.05, so you would fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a634cb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Likelihood Estimate for p_release: 0.50\n",
      "Probability of observing 7 quanta with p_release = 0.50 given true p_release = 0.30: 0.2095\n",
      "Probability of observing 7 quanta with p_release = 0.30 given true p_release = 0.30: 0.0618\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "# Given data\n",
    "observed_quanta = 7\n",
    "total_quanta = 14\n",
    "true_p_release = 0.3\n",
    "\n",
    "# Function to compute the negative log-likelihood\n",
    "def negative_log_likelihood(p_release):\n",
    "    likelihood = binom.pmf(observed_quanta, total_quanta, p_release)\n",
    "    return -np.log(likelihood)\n",
    "\n",
    "# Find the maximum likelihood estimate for p_release\n",
    "result = minimize_scalar(negative_log_likelihood, bounds=(0, 1), method='bounded')\n",
    "\n",
    "# The MLE estimate for p_release\n",
    "mle_p_release = result.x\n",
    "\n",
    "print(f\"Maximum Likelihood Estimate for p_release: {mle_p_release:.2f}\")\n",
    "\n",
    "# Calculate the probability of obtaining the MLE estimate given the true p_release\n",
    "likelihood_at_mle = binom.pmf(observed_quanta, total_quanta, mle_p_release)\n",
    "probability_given_true = binom.pmf(observed_quanta, total_quanta, true_p_release)\n",
    "\n",
    "print(f\"Probability of observing {observed_quanta} quanta with p_release = {mle_p_release:.2f} given true p_release = {true_p_release:.2f}: {likelihood_at_mle:.4f}\")\n",
    "print(f\"Probability of observing {observed_quanta} quanta with p_release = {true_p_release:.2f} given true p_release = {true_p_release:.2f}: {probability_given_true:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0728534c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
